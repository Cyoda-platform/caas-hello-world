{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e3c4172b-2e37-487d-80e0-8d1fd4cea0a2",
   "metadata": {},
   "source": [
    "# Overview\n",
    "In this notebook we will run a simple illustration on how to \n",
    "1. Import workflow configuration into your Cyoda environment\n",
    "2. Register entity models with Cyoda so that you can save entities\n",
    "3. Save an entity for a given model\n",
    "4. Run a search and retrieve it's results\n",
    "\n",
    "## Nobel Prizes dataset\n",
    "We will use two models related to Nobel Prize data. The first is a dataset structure containing a list of Nobel Prizes. The second is a single Nobel Prize for a given category and year. The workflow for the dataset is configured to call a Processor that dissects the data set and saves each Nobel Prize in the set as single Nobel Prize entity. See the Kotlin code for more details. \n",
    "\n",
    "Basically, when the dataset is saved, its workflow will trigger the processor and create hundreds of single prizes.\n",
    "\n",
    "## Prerequites\n",
    "1. You need to have your username and password ready.\n",
    "2. Your Cyoda environment must be up and running.\n",
    "3. The Spring Boot `SimpleExampleCyodaClient` application that connects to Cyoda as a compute node has to be running.\n",
    "\n",
    "# Install required libs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfa36a13-28cf-4051-91c8-555191056644",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install tzlocal"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c9eeb91",
   "metadata": {},
   "source": [
    "# Define your connection parameters and credentials\n",
    "## Set your namespace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e3075ae6-5c8e-4644-8838-13b761181d2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "namespace = 'put your Cyoda namespace here'\n",
    "api_url = f\"https://{namespace}.cyoda.net/api\"\n",
    "\n",
    "# If you have a Cyoda Platform license, you might have Cyoda running locally on your laptop. \n",
    "#api_url = 'http://localhost:8082/api'\n",
    "\n",
    "login_endpoint = f\"{api_url}/auth/login\"\n",
    "token_endpoint = f\"{api_url}/auth/token\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f88ef45f",
   "metadata": {},
   "source": [
    "## Set your credentials\n",
    "To avoid being prompts for a password to connect, you can set an environment variable `DEMO_USER_PASSWD`, for example in your personal github Codespace Secrets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0bf8d1ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import getpass\n",
    "import os\n",
    "\n",
    "default_username = 'demo.user'\n",
    "\n",
    "username = default_username\n",
    "password = os.getenv('DEMO_USER_PASSWD')\n",
    "\n",
    "# If the environment variable is not set, check the password file (only relevant when running this book locally)\n",
    "if not password:\n",
    "    password_file = Path('/Users/paul/.cyoda/demo.passwd')\n",
    "\n",
    "    if password_file.exists():\n",
    "        # Read the password from the file\n",
    "        with password_file.open('r') as file:\n",
    "            password = file.read().rstrip()\n",
    "    else:\n",
    "        # Prompt for credentials when no env variable or file is available\n",
    "        password = getpass.getpass(\"Enter your password: \")\n",
    "\n",
    "credentials = {\n",
    "    'username': username,\n",
    "    'password': password\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7019964",
   "metadata": {},
   "source": [
    "# Import your workflow configuration\n",
    "Import everying from the config directory using the `cyoda_config_ctl.py` script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11918864",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_dir = 'src/main/resources/cyoda/config/nobel-prizes/cyoda-config'\n",
    "\n",
    "!{sys.executable} src/tools/cyoda_config_ctl.py \\\n",
    "    -m 'import' \\\n",
    "    -host \"{api_url}\" \\\n",
    "    -u \"{username}\" \\\n",
    "    -pw \"{password}\" \\\n",
    "    -fd \"{target_dir}\" \\\n",
    "    --need_to_import_state_machine true"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82fa4752-1f20-466d-b250-41b34f8f7b72",
   "metadata": {},
   "source": [
    "# Some Functions\n",
    "To do this work, we need to do a bunch of HTTP API requests to your Cyoda environment.\n",
    "\n",
    "I'm a python noob, so I'm just going to write lots of old school functions that interact with Cyoda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ffcba5a3-ba14-444d-b04b-08752ccdddfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import time\n",
    "from datetime import datetime\n",
    "import tzlocal  # For detecting local timezone\n",
    "\n",
    "def login_and_get_refresh_token(credentials):\n",
    "\n",
    "    headers = {\n",
    "        'X-Requested-With': 'XMLHttpRequest',\n",
    "        'Content-Type': 'application/json'\n",
    "    }\n",
    "    \n",
    "    payload = json.dumps(credentials)\n",
    "    \n",
    "    response = requests.post(login_endpoint, headers=headers, data=payload)\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        # Assuming the refresh token is returned in the 'refresh_token' field\n",
    "        refresh_token = response.json().get('refreshToken')\n",
    "        return refresh_token\n",
    "    else:\n",
    "        raise Exception(f\"Login failed: {response.status_code} {response.text}\")\n",
    "    \n",
    "#############################################################################\n",
    "# Get an access token from the refresh token\n",
    "#############################################################################\n",
    "def get_access_token(refresh_token):\n",
    "    headers = {\n",
    "        'Content-Type': 'application/json',\n",
    "        'Authorization': f'Bearer {refresh_token}'\n",
    "    }\n",
    "    response = requests.get(token_endpoint, headers=headers)\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        token_data = response.json()\n",
    "        access_token = token_data.get('token')\n",
    "        #token_expiry = token_data.get('tokenExpiry')\n",
    "        return access_token\n",
    "    else:\n",
    "        raise Exception(f\"Token refresh failed: {response.status_code} {response.text}\")\n",
    "\n",
    "#############################################################################\n",
    "# Check if the given model exists\n",
    "#############################################################################\n",
    "def model_exists(model_name,model_version):\n",
    "    export_model_url = f\"{api_url}/treeNode/model/export/SIMPLE_VIEW/{model_name}/{model_version}\"\n",
    "    \n",
    "    response = requests.get(export_model_url, headers=headers)\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        return True\n",
    "    elif response.status_code == 404:\n",
    "        return False\n",
    "    else:\n",
    "        raise Exception(f\"Get: {response.status_code} {response.text}\")\n",
    "\n",
    "\n",
    "#############################################################################\n",
    "# Get the definition of a model\n",
    "#############################################################################\n",
    "def get_model(model_name,model_version):\n",
    "    export_model_url = f\"{api_url}/treeNode/model/export/SIMPLE_VIEW/{model_name}/{model_version}\"\n",
    "    \n",
    "    response = requests.get(export_model_url,headers=headers)\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        return response.json()\n",
    "    else:\n",
    "        raise Exception(f\"Getting the model failed: {response.status_code} {response.text}\")\n",
    "\n",
    "\n",
    "#############################################################################\n",
    "# Get the state of the model, i.er. LOCKED or UNLOCKED\n",
    "#############################################################################\n",
    "def get_model_state(model_name,model_version):\n",
    "    export_model_url = f\"{api_url}/treeNode/model/export/SIMPLE_VIEW/{model_name}/{model_version}\"\n",
    "    \n",
    "    response = requests.get(export_model_url,headers=headers)\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        return response.json().get('currentState')            \n",
    "    else:\n",
    "        raise Exception(f\"Failed to get the model: {response.status_code} {response.text}\")  \n",
    "\n",
    "\n",
    "#############################################################################\n",
    "# Unlock a model. Will only succeed if there is no data for that model\n",
    "#############################################################################\n",
    "def unlock_model(model_name,model_version):\n",
    "    unlock_model_url = f\"{api_url}/treeNode/model/{model_name}/{model_version}/unlock\"\n",
    "\n",
    "    response = requests.put(unlock_model_url,headers=headers)\n",
    "    if response.status_code == 200:\n",
    "        print('model unlocked')\n",
    "    else:\n",
    "        raise Exception(f\"Unlock failed: {response.status_code} {response.text}\")\n",
    "\n",
    "\n",
    "#############################################################################\n",
    "# Lock a model. You cannot save data for a model until it is LOCKED\n",
    "#############################################################################\n",
    "def lock_model(model_name,model_version):\n",
    "    lock_model_url = f\"{api_url}/treeNode/model/{model_name}/{model_version}/lock\"\n",
    "\n",
    "    response = requests.put(lock_model_url,headers=headers)\n",
    "    if response.status_code == 200:\n",
    "        print('model locked')\n",
    "    else:\n",
    "        raise Exception(f\"Lock failed: {response.status_code} {response.text}\")\n",
    "\n",
    "\n",
    "#############################################################################\n",
    "# Delete a model. You can only delete a model that is UNLOCKED\n",
    "#############################################################################\n",
    "def delete_model(model_name,model_version):\n",
    "    model_url               = f\"{api_url}/treeNode/model/{model_name}/{model_version}\"\n",
    "    \n",
    "    response = requests.delete(model_url,headers=headers)\n",
    "    if response.status_code == 200:\n",
    "        print('model deleted')\n",
    "    else:\n",
    "        raise Exception(f\"Deletion of the model failed: {response.status_code} {response.text}\")\n",
    "\n",
    "\n",
    "def calculate_total_entities_removed(json_string):\n",
    "    # Parse the JSON string into a Python list\n",
    "    data = json.loads(json_string)\n",
    "    \n",
    "    # Initialize the total counter\n",
    "    total_entities_removed = 0\n",
    "    \n",
    "    # Iterate through each entry and accumulate the number of removed entities\n",
    "    for entry in data:\n",
    "        total_entities_removed += entry['deleteResult']['numberOfEntititesRemoved']\n",
    "    \n",
    "    return total_entities_removed\n",
    "\n",
    "\n",
    "#############################################################################\n",
    "# Delete all data for a given model\n",
    "#############################################################################\n",
    "def delete_all_entities(model_name,model_version):\n",
    "    delete_entities_url = f\"{api_url}/entity/TREE/{model_name}/{model_version}\"\n",
    "\n",
    "    params = {\n",
    "        'pageSize': '1000',\n",
    "        'transactionSize': '1000'\n",
    "    }\n",
    "    response = requests.delete(delete_entities_url, headers=headers, params=params)\n",
    "\n",
    "    if response.status_code == 200:\n",
    "    \n",
    "        # Initialize the total counter\n",
    "        total_entities_removed = 0\n",
    "    \n",
    "        # Iterate through each entry and accumulate the number of removed entities\n",
    "        for entry in response.json():\n",
    "            total_entities_removed += entry['deleteResult']['numberOfEntititesRemoved']\n",
    "        return total_entities_removed\n",
    "    \n",
    "    else:\n",
    "        raise Exception(f\"Deletion failed: {response.status_code} {response.text}\")\n",
    "\n",
    "\n",
    "#############################################################################\n",
    "# Specify a model via sample data\n",
    "#############################################################################\n",
    "def derive_model_from_sample_data(model_name,model_version,payload):\n",
    "    import_model_url = f\"{api_url}/treeNode/model/import/JSON/SAMPLE_DATA/{model_name}/{model_version}\"\n",
    "    response = requests.post(import_model_url, headers=headers, data=payload)\n",
    "    if response.status_code == 200:\n",
    "        return response.text\n",
    "    else:\n",
    "        raise Exception(f\"Save failed: {response.status_code} {response.text}\")\n",
    "        \n",
    "#############################################################################\n",
    "# Reset a model, i.e.\n",
    "#   - check if it exists, and if so delete all data for that model, then\n",
    "#        unlock it and delete it\n",
    "#   - (re)create the model from the sample data of the given file and lock it\n",
    "#############################################################################\n",
    "def reset_model(model_name, model_version, file_path):\n",
    "    print(f\"Resetting model '{model_name}' version {model_version}\")\n",
    "    \n",
    "    is_an_existing_model = model_exists(model_name,model_version)\n",
    "    \n",
    "    if is_an_existing_model: \n",
    "        print(f\"Deleting all data for model '{model_name}' version {model_version}\")\n",
    "        delete_result = delete_all_entities(model_name,model_version)\n",
    "        print(f\"Total entities deleted: {delete_result}\")\n",
    "        \n",
    "        current_model_state = get_model_state(model_name,model_version)\n",
    "        \n",
    "        if current_model_state == 'LOCKED':\n",
    "            unlock_model(model_name,model_version)\n",
    "        else:\n",
    "            print('Model not locked')\n",
    "    \n",
    "        delete_model(model_name,model_version)\n",
    "    else:\n",
    "        print(f\"model {model_name} {model_version} doesn't exist. Nothing to do\")\n",
    "\n",
    "    with open(file_path, 'r') as file:\n",
    "         file_contents = json.load(file)\n",
    "    \n",
    "    payload = json.dumps(file_contents)\n",
    "    \n",
    "    model_id = derive_model_from_sample_data(model_name,model_version,payload)\n",
    "    \n",
    "    print(f\"model id = {model_id}\")\n",
    "\n",
    "    lock_model(model_name,model_version)\n",
    "    print('Model locked')\n",
    "\n",
    "#############################################################################\n",
    "# Save a new entity for the given JSON representation\n",
    "#############################################################################\n",
    "def create_entity(model_name,model_version,json_payload):\n",
    "    create_entity_url = f\"{api_url}/entity/JSON/TREE/{model_name}/{model_version}\"\n",
    "\n",
    "    params = {\n",
    "        'transactionTimeoutMillis': '10000'\n",
    "    }\n",
    "\n",
    "    response = requests.post(create_entity_url, headers=headers, params=params, data=json_payload)\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        json_response = response.json()\n",
    "        print(response.text)\n",
    "        \n",
    "        # Assert that there is only one transaction\n",
    "        assert len(json_response) == 1, f\"Expected 1 transaction, but got {len(json_response)}\"\n",
    "        \n",
    "        transaction = json_response[0]\n",
    "        entity_ids = transaction['entityIds']\n",
    "        \n",
    "        # Assert that the list of entityIds has exactly one element\n",
    "        assert len(entity_ids) == 1, f\"Expected 1 entityId, but got {len(entity_ids)}\"\n",
    "        \n",
    "        return entity_ids[0]\n",
    "    else:\n",
    "        raise Exception(f\"Save failed: {response.status_code} {response.text}\")\n",
    "\n",
    "#############################################################################\n",
    "# Get entities for a given model. This is paged, so you need to provide \n",
    "# the page size and page number. \n",
    "#\n",
    "# We still need to provide in the Cyoda backend the statistics endpoints \n",
    "# for model data and also enhance this endpoint to provide HATEOAS links \n",
    "# to make it easier to page through all data. It's a work-in-progress\n",
    "#############################################################################\n",
    "def get_all_entities(model_name,model_version,page_size,page_number):\n",
    "    delete_entities_url = f\"{api_url}/entity/TREE/{model_name}/{model_version}\"\n",
    "\n",
    "    params = {\n",
    "        'pageSize': f\"{page_size}\",\n",
    "        'pageNumber': f\"{page_number}\"\n",
    "    }\n",
    "\n",
    "    response = requests.get(delete_entities_url, headers=headers, params=params)\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        return response.json()\n",
    "    else:\n",
    "        raise Exception(f\"Get all entities failed: {response.status_code} {response.text}\")\n",
    "\n",
    "#############################################################################\n",
    "# Trigger a search for entities for the given condition \n",
    "#############################################################################\n",
    "def create_snapshot_search(model_name,model_version,condition):\n",
    "    search_url = f\"{api_url}/treeNode/search/snapshot/{model_name}/{model_version}\"\n",
    "\n",
    "    response = requests.post(search_url, headers=headers, data=json.dumps(condition))\n",
    "    if response.status_code == 200:\n",
    "        return response.json()\n",
    "    else:\n",
    "        raise Exception(f\"Snapshot search trigger failed: {response.status_code} {response.text}\")\n",
    "\n",
    "#############################################################################\n",
    "# Check the status of the snapshot search\n",
    "#############################################################################\n",
    "def get_snapshot_status(snapshot_id):\n",
    "    status_url = f\"{api_url}/treeNode/search/snapshot/{snapshot_id}/status\"\n",
    "\n",
    "    response = requests.get(status_url, headers=headers)\n",
    "    if response.status_code == 200:\n",
    "        return response.json()\n",
    "    else:\n",
    "        raise Exception(f\"Snapshot search trigger failed: {response.status_code} {response.text}\")\n",
    "\n",
    "\n",
    "#############################################################################\n",
    "# Wait for the completion of the snapshot search until a timeout is reached\n",
    "#############################################################################\n",
    "def wait_for_search_completion(snapshot_id, timeout=5, interval=10):\n",
    "    \"\"\"\n",
    "    Waits until the status is 'completed' or 'failed', or the timeout is exceeded.\n",
    "    \n",
    "    Parameters:\n",
    "    - timeout: Max time to wait in seconds.\n",
    "    - interval: Time to wait between status checks in msec.\n",
    "    \n",
    "    Returns:\n",
    "    - snapshot status response if the task finishes successfully.\n",
    "    - Raises an Exception if the timeout is exceeded or the task fails.\n",
    "    \"\"\"\n",
    "    start_time = time.time()  # Record the start time\n",
    "    \n",
    "    while True:\n",
    "        status_response = get_snapshot_status(snapshot_id)\n",
    "        status = status_response.get(\"snapshotStatus\")\n",
    "        \n",
    "        # Check if the status is SUCCESSFUL or FAILED\n",
    "        if status == \"SUCCESSFUL\":\n",
    "            return status_response\n",
    "        elif status != \"RUNNING\":\n",
    "            raise Exception(f\"Snapshot search failed: {json.dumps(status_response, indent=4)}\")\n",
    "        \n",
    "        elapsed_time = time.time() - start_time\n",
    "        \n",
    "        if elapsed_time > timeout:\n",
    "            raise TimeoutError(f\"Timeout exceeded after {timeout} seconds\")\n",
    "        \n",
    "        time.sleep(interval/1000)  # Wait for the given interval (msec) before checking again\n",
    "\n",
    "def get_search_result(snapshot_id,page_size,page_number):\n",
    "    result_url = f\"{api_url}/treeNode/search/snapshot/{snapshot_id}\"\n",
    "\n",
    "    params = {\n",
    "        'pageSize': f\"{page_size}\",\n",
    "        'pageNumber': f\"{page_number}\"\n",
    "    }\n",
    "\n",
    "    response = requests.get(result_url, headers=headers, params=params)\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        return response.json()\n",
    "    else:\n",
    "        raise Exception(f\"Get search result failed: {response.status_code} {response.text}\")\n",
    "\n",
    "\n",
    "#############################################################################\n",
    "# Search for entities\n",
    "#############################################################################    \n",
    "def search_entities(model_name,model_version,condition):\n",
    "    snapshot_id = create_snapshot_search(model_name,model_version,condition)\n",
    "    status_response = wait_for_search_completion(snapshot_id)\n",
    "    status_response['snapshotId'] = snapshot_id\n",
    "    return status_response\n",
    "\n",
    "#############################################################################\n",
    "# For pretty printing of an ISO formatted datetime\n",
    "#############################################################################    \n",
    "def convert_to_local_time(iso_string):\n",
    "    \"\"\"\n",
    "    Convert an ISO 8601 formatted datetime string to the local timezone.\n",
    "\n",
    "    :param iso_string: A string representing the datetime in ISO 8601 format\n",
    "    :return: A string with the datetime in the local timezone, formatted as 'YYYY-MM-DD HH:MM:SS TZ (offset)'\n",
    "    \"\"\"\n",
    "    # Parse the ISO 8601 string\n",
    "    parsed_date = datetime.fromisoformat(iso_string)\n",
    "\n",
    "    # Detect the local timezone dynamically\n",
    "    local_timezone = tzlocal.get_localzone()\n",
    "\n",
    "    # Convert the parsed datetime to the detected local timezone\n",
    "    local_date = parsed_date.astimezone(local_timezone)\n",
    "\n",
    "    # Format the datetime in a human-readable form with the timezone\n",
    "    return local_date.strftime('%Y-%m-%d %H:%M:%S %Z (%z)')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc735e72-13db-4d3a-95ab-e0d91a9d8300",
   "metadata": {},
   "source": [
    "# Reset the data models\n",
    "We'll be using two models: a collection of Nobel Prizes and an individual Nobel Prize.\n",
    "In workflow, the collection will be dissected and for each an individual Nobel Prize saved.\n",
    "\n",
    "To reset a model, we first check if the model exists and if so delete all data for that model, then unlock it and delete the model itself. We can do this, because it's a sandbox here. In real life, we would need to open up a new model version and either live with multple versions, or migrate data from one version to the next.\n",
    "\n",
    "Once it's deleted, we'll create it again, using the appropriate sample data. Before saving any entities, we have to lock the model, so that it is immutable, because a model must always be consistent with its entities. If you want to change a model after you have saved data for it, you must open up a new version for that model.\n",
    "\n",
    "The paradigm is that models are immutable when data is attached."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f18c88d-3b41-4226-9301-52f6acffc096",
   "metadata": {},
   "outputs": [],
   "source": [
    "refresh_token = login_and_get_refresh_token(credentials=credentials)\n",
    "access_token = get_access_token(refresh_token=refresh_token)\n",
    "headers = {\n",
    "        'Content-Type': 'application/json',\n",
    "        'Authorization': f'Bearer {access_token}'\n",
    "    }\n",
    "\n",
    "prizes_model = 'prizes'\n",
    "prizes_sample = './src/main/resources/cyoda/config/nobel-prizes/sample-data/prize-physics-2019.json'\n",
    "\n",
    "single_prize_model = 'prize'\n",
    "single_prize_sample = './src/main/resources/cyoda/config/nobel-prizes/sample-data/single-prize-physics-2019.json'\n",
    "\n",
    "model_version = 1\n",
    "\n",
    "print(\"WARNING: Deleting lots of entities is still slow. Be patient and wait for the DONE signal\")\n",
    "\n",
    "reset_model(prizes_model,model_version,prizes_sample)\n",
    "reset_model(single_prize_model,model_version,single_prize_sample)\n",
    "\n",
    "print('DONE with reset')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c14acec4-b09c-418c-a2bc-2f08f9e9488a",
   "metadata": {},
   "source": [
    "# Post the Nobel Prizes full dataset\n",
    "We now can post the full Nobel Prize dataset. It'll be a large entity and is fully searchable. But for illustration purposes we will use workflow to dissect each item in the dataset to create a new entity for each Nobel Prize."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f43994f4-a3da-4780-98e6-c9313a1bd533",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This dataset in only a partial list of all prizes\n",
    "file_path = './src/main/resources/cyoda/config/nobel-prizes/sample-data/prize.json'\n",
    "\n",
    "with open(file_path, 'r') as file:\n",
    "    file_contents = json.load(file)\n",
    "    \n",
    "json_payload = json.dumps(file_contents)\n",
    "entity_id = create_entity(prizes_model,model_version,json_payload) \n",
    "print(f\"Entity Id = {entity_id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d98c2887-c0ce-4783-8e52-39fb297884fc",
   "metadata": {},
   "source": [
    "# Check result\n",
    "See if we have created individual Nobel Prizes entities in workflow. \n",
    "\n",
    "We will use the snapshot search API. This runs a snapshot search for the given condition, which will use indexing wherever possible. The search is done with horizontal scalability, meaning that each of the Cyoda nodes for your environment will do a part of the work (i.e. the search is sharded across the cluster). If your queries involve full table scans, you can linearly increase the performance by adding more Cyoda nodes to your environment. The query is resillient against node failures, by the way. The cluster redistributes the work automatically. Unless something really bad happens, your query will always return a result, even if nodes fail while the query is running.\n",
    "\n",
    "After launching the query, check the status until the report completes or a timeout is reached. Once complete, print the first page.\n",
    "\n",
    "Snapshot search results are available for a certain amount of time and then are automatically deleted. You can find out how long the results are available from the search status request."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31de8d54-c913-4e2c-8f20-49c32d859fdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "condition = {\n",
    "    \"operator\": \"AND\",\n",
    "    \"conditions\": [\n",
    "        {\n",
    "            \"jsonPath\": \"$.dataSetId\",\n",
    "            \"operatorType\": \"EQUALS\",\n",
    "            \"value\": f\"{entity_id}\",\n",
    "            \"type\": \"simple\"\n",
    "        }\n",
    "    ],\n",
    "    \"type\": \"group\"\n",
    "}\n",
    "\n",
    "search_status = search_entities(single_prize_model,model_version,condition)\n",
    "\n",
    "print(f\"Found {search_status.get(\"entitiesCount\")} entities\")\n",
    "expiration_date = convert_to_local_time(search_status.get(\"expirationDate\"))\n",
    "print(f\"Snapshot will expire on {expiration_date}\")\n",
    "\n",
    "snapshot_id = search_status['snapshotId']\n",
    "first_page = get_search_result(snapshot_id,page_size=10,page_number=1)\n",
    "\n",
    "print(json.dumps(first_page, indent=4))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
